{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333ae546d607a744",
   "metadata": {},
   "source": [
    "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
    "\n",
    "## Objective:\n",
    "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8de51df",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "* Follow the steps outlined above to implement the IR system.\n",
    "* Run the provided code snippets to understand how each part of the system works.\n",
    "* Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
    "* Compare and analyze the results. Discuss the pros and cons of each method.\n",
    "* Document your findings and any improvements you make to the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b02fd2",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Import Libraries\n",
    "Import necessary libraries for data handling, text processing, and machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7265c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "#from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9104ebc",
   "metadata": {},
   "source": [
    "\n",
    "### Step 2: Load the Dataset\n",
    "\n",
    "Load the dataset of podcast transcripts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9038e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id            guest                    title  \\\n",
      "0   1      Max Tegmark                 Life 3.0   \n",
      "1   2    Christof Koch            Consciousness   \n",
      "2   3    Steven Pinker  AI in the Age of Reason   \n",
      "3   4    Yoshua Bengio            Deep Learning   \n",
      "4   5  Vladimir Vapnik     Statistical Learning   \n",
      "\n",
      "                                                text  \n",
      "0  As part of MIT course 6S099, Artificial Genera...  \n",
      "1  As part of MIT course 6S099 on artificial gene...  \n",
      "2  You've studied the human mind, cognition, lang...  \n",
      "3  What difference between biological neural netw...  \n",
      "4  The following is a conversation with Vladimir ...  \n"
     ]
    }
   ],
   "source": [
    "# Ruta al archivo .csv\n",
    "file_path = 'D:\\\\U\\\\7. Septimo\\\\RI\\\\ir24a\\\\week11\\\\data\\\\podcastdata_dataset.csv'\n",
    "\n",
    "# Cargar el archivo .csv en un DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b47fd4",
   "metadata": {},
   "source": [
    "\n",
    "### Step 3: Text Preprocessing\n",
    "\n",
    "You know what to do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c79bb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\matte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\matte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ca36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-procesamiento de texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuación\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenizar\n",
    "    words = word_tokenize(text)\n",
    "    # Eliminar palabras vacías\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    # Unir palabras procesadas en una sola cadena\n",
    "    processed_text = ' '.join(words)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a5bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el preprocesamiento a una columna específica del DataFrame\n",
    "# Supongamos que la columna de interés se llama 'text'\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2410060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  As part of MIT course 6S099, Artificial Genera...   \n",
      "1  As part of MIT course 6S099 on artificial gene...   \n",
      "2  You've studied the human mind, cognition, lang...   \n",
      "3  What difference between biological neural netw...   \n",
      "4  The following is a conversation with Vladimir ...   \n",
      "\n",
      "                                      processed_text  \n",
      "0  part mit cours 6s099 artifici gener intellig i...  \n",
      "1  part mit cours 6s099 artifici gener intellig g...  \n",
      "2  youv studi human mind cognit languag vision ev...  \n",
      "3  differ biolog neural network artifici neural n...  \n",
      "4  follow convers vladimir vapnik he co inventor ...  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del DataFrame procesado\n",
    "print(df[['text', 'processed_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75cc8c1",
   "metadata": {},
   "source": [
    "\n",
    "###  Step 4: Vector Space Representation - TF-IDF\n",
    "\n",
    "Create TF-IDF vector representations of the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c874914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear representaciones TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['processed_text'])\n",
    "\n",
    "# Convertir la matriz TF-IDF a un DataFrame para su visualización\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las primeras filas del DataFrame TF-IDF\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae4872",
   "metadata": {},
   "source": [
    "\n",
    "### Step 5: Vector Space Representation - BERT\n",
    "\n",
    "Create BERT vector representations of the transcripts using a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo preentrenado de BERT y el tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdad850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener las representaciones de BERT\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenización y codificación\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    # Obtener las representaciones del modelo BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Usar el embedding de la primera palabra ([CLS])\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    return embeddings.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función de embeddings a la columna 'processed_text'\n",
    "df['bert_embeddings'] = df['processed_text'].apply(get_bert_embeddings)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame con los embeddings BERT\n",
    "print(df[['text', 'bert_embeddings']].head())\n",
    "\n",
    "# Convertir las representaciones de BERT a una matriz\n",
    "bert_matrix = np.vstack(df['bert_embeddings'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d4732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las dimensiones de la matriz de embeddings BERT\n",
    "print(bert_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d1091",
   "metadata": {},
   "source": [
    "\n",
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3f180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c2661bf",
   "metadata": {},
   "source": [
    "\n",
    "### Step 7: Retrieve and Compare Results\n",
    "\n",
    "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f0911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "247dd4a7",
   "metadata": {},
   "source": [
    "\n",
    "### Step 8: Test the IR System\n",
    "\n",
    "Test the system with a sample query.\n",
    "\n",
    "Retrieve and display the top results using both TF-IDF and BERT representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9500a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f907051e",
   "metadata": {},
   "source": [
    "\n",
    "### Step 9: Compare Results\n",
    "\n",
    "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
    "\n",
    "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e10f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
